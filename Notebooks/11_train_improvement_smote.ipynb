{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30729790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitta-bitta bosib train qilasiz, va model doim:\n",
    "\n",
    "# Models/improvement_models/with_SMOTE_improvement_train/\n",
    "\n",
    "# ga saqlanadi. Root topishda ham Notebooks tuzog‘iga tushmaydi (Data fayllar bor joydan topadi).\n",
    "\n",
    "# ⚠️ Eslatma (muhim): TF-IDF sparse feature’da SMOTE to‘g‘ridan-to‘g‘ri ishlasa RAM portlashi mumkin. Shuning uchun bu yerda TruncatedSVD (dim reduction) → SMOTE → classifier pipeline qilamiz. Bu SMOTE uchun eng amaliy yo‘l.\n",
    "\n",
    "# CELL 1 — Imports\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "\n",
    "# models\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# dim reduction\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# SMOTE\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        \"imblearn topilmadi. O‘rnating:\\n\"\n",
    "        \"pip install imbalanced-learn\\n\"\n",
    "        f\"Original error: {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0140ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\n",
      "DATA_SOURCE: Feature_Selected\n",
      "DATA_DIR: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\\Data\\Feature_Selected\\fe_v1_fs_chi2_v1\n",
      "SAVE_DIR: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\\Models\\improvement_models\\with_SMOTE_improvement_train\n",
      "RESULTS_DIR: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\\results\\improvement_smote\\smote_20260225_233337\n",
      "Num labels: 21\n",
      "X shapes: (201176, 33671) (24410, 33671) (24164, 33671)\n",
      "Y shapes: (201176, 21) (24410, 21) (24164, 21)\n"
     ]
    }
   ],
   "source": [
    "#CELL 2 — Config + PROJECT_ROOT (adashmaydi) + Load X/Y (Feature_Selected yoki Engineered_data)\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "DATA_VERSION = \"fe_v1_fs_chi2_v1\"   # Feature_Selected bo‘lsa shuni ishlating (tavsiya)\n",
    "# DATA_VERSION = \"fe_v1\"           # agar Feature_Selected yo‘q bo‘lsa, Engineered_data\n",
    "\n",
    "PREFER_FEATURE_SELECTED = True     # avval Data/Feature_Selected dan qidirsin\n",
    "N_JOBS = 1\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# SVD komponentlar (SMOTE uchun)\n",
    "SVD_N_COMPONENTS = 300  # xohlasangiz 200/300/500\n",
    "\n",
    "# Threshold tuning\n",
    "N_THR = 61\n",
    "\n",
    "# Save model dir (aytgan joy)\n",
    "SAVE_DIR_REL = Path(\"Models\") / \"improvement_models\" / \"with_SMOTE_improvement_train\"\n",
    "RESULTS_DIR_REL = Path(\"results\") / \"improvement_smote\"\n",
    "\n",
    "def find_project_root_by_dataset(version: str, prefer_fs: bool = True, start: Path | None = None):\n",
    "    \"\"\"\n",
    "    PROJECT_ROOT ni Notebooks deb olmaydi.\n",
    "    Mezoni: Data/Feature_Selected/<ver>/X_train.npz yoki Data/Engineered_data/<ver>/X_train.npz bor joy.\n",
    "    \"\"\"\n",
    "    start = start or Path.cwd()\n",
    "    checked = []\n",
    "    for p in [start] + list(start.parents):\n",
    "        fs_dir = p / \"Data\" / \"Feature_Selected\" / version\n",
    "        en_dir = p / \"Data\" / \"Engineered_data\" / version\n",
    "\n",
    "        checked.append((fs_dir, en_dir))\n",
    "\n",
    "        if prefer_fs and (fs_dir / \"X_train.npz\").exists() and (fs_dir / \"Y_train.npy\").exists() and (fs_dir / \"engineered_meta.json\").exists():\n",
    "            return p, fs_dir, \"Feature_Selected\"\n",
    "        if (en_dir / \"X_train.npz\").exists() and (en_dir / \"Y_train.npy\").exists() and (en_dir / \"engineered_meta.json\").exists():\n",
    "            return p, en_dir, \"Engineered_data\"\n",
    "        if (fs_dir / \"X_train.npz\").exists() and (fs_dir / \"Y_train.npy\").exists() and (fs_dir / \"engineered_meta.json\").exists():\n",
    "            return p, fs_dir, \"Feature_Selected\"\n",
    "\n",
    "    # helpful message\n",
    "    last = checked[-5:] if checked else []\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset topilmadi. version={version}\\n\"\n",
    "        f\"Start: {start.resolve()}\\n\"\n",
    "        \"Oxirgi tekshirilgan joylar (FS, ENG):\\n\"\n",
    "        + \"\\n\".join([f\"- {a} | {b}\" for a,b in last]) +\n",
    "        \"\\n\\nYECHIM:\\n\"\n",
    "        \"Avval 09_feature_engineering va (bo‘lsa) 09b_feature_selection ni run qiling.\"\n",
    "    )\n",
    "\n",
    "PROJECT_ROOT, DATA_DIR, DATA_SOURCE = find_project_root_by_dataset(DATA_VERSION, PREFER_FEATURE_SELECTED)\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT.resolve())\n",
    "print(\"DATA_SOURCE:\", DATA_SOURCE)\n",
    "print(\"DATA_DIR:\", DATA_DIR.resolve())\n",
    "\n",
    "SAVE_DIR = PROJECT_ROOT / SAVE_DIR_REL\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"SAVE_DIR:\", SAVE_DIR.resolve())\n",
    "\n",
    "RESULTS_DIR = PROJECT_ROOT / RESULTS_DIR_REL / datetime.now().strftime(\"smote_%Y%m%d_%H%M%S\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"RESULTS_DIR:\", RESULTS_DIR.resolve())\n",
    "\n",
    "# ---- load meta ----\n",
    "with open(DATA_DIR / \"engineered_meta.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "y_cols = meta[\"y_cols\"]\n",
    "print(\"Num labels:\", len(y_cols))\n",
    "\n",
    "# ---- load X/Y ----\n",
    "X_train = sparse.load_npz(DATA_DIR / \"X_train.npz\").tocsr()\n",
    "X_val   = sparse.load_npz(DATA_DIR / \"X_val.npz\").tocsr()\n",
    "X_test  = sparse.load_npz(DATA_DIR / \"X_test.npz\").tocsr()\n",
    "\n",
    "Y_train = np.load(DATA_DIR / \"Y_train.npy\")\n",
    "Y_val   = np.load(DATA_DIR / \"Y_val.npy\")\n",
    "Y_test  = np.load(DATA_DIR / \"Y_test.npy\")\n",
    "\n",
    "print(\"X shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"Y shapes:\", Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ca6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL 3 — Helpers (metrics + threshold tuning) ✅ (NameError bo‘lmasin)\n",
    "def prf_from_counts(tp: int, fp: int, fn: int):\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1   = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
    "    return prec, rec, f1\n",
    "\n",
    "def multilabel_micro_macro(Y_true: np.ndarray, Y_pred: np.ndarray) -> dict:\n",
    "    tp = int(((Y_true == 1) & (Y_pred == 1)).sum())\n",
    "    fp = int(((Y_true == 0) & (Y_pred == 1)).sum())\n",
    "    fn = int(((Y_true == 1) & (Y_pred == 0)).sum())\n",
    "    micro_p, micro_r, micro_f1 = prf_from_counts(tp, fp, fn)\n",
    "\n",
    "    f1s, ps, rs = [], [], []\n",
    "    for j in range(Y_true.shape[1]):\n",
    "        y = Y_true[:, j]\n",
    "        p = Y_pred[:, j]\n",
    "        tpj = int(((y == 1) & (p == 1)).sum())\n",
    "        fpj = int(((y == 0) & (p == 1)).sum())\n",
    "        fnj = int(((y == 1) & (p == 0)).sum())\n",
    "        pj_, rj_, f1j_ = prf_from_counts(tpj, fpj, fnj)\n",
    "        ps.append(pj_); rs.append(rj_); f1s.append(f1j_)\n",
    "    return {\n",
    "        \"micro_precision\": float(micro_p),\n",
    "        \"micro_recall\": float(micro_r),\n",
    "        \"micro_f1\": float(micro_f1),\n",
    "        \"macro_precision\": float(np.mean(ps)),\n",
    "        \"macro_recall\": float(np.mean(rs)),\n",
    "        \"macro_f1\": float(np.mean(f1s)),\n",
    "    }\n",
    "\n",
    "def score_matrix(model, X):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        P = model.predict_proba(X)\n",
    "        return np.asarray(P), \"proba\"\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        S = model.decision_function(X)\n",
    "        return np.asarray(S), \"score\"\n",
    "    Yp = model.predict(X)\n",
    "    return np.asarray(Yp), \"binary\"\n",
    "\n",
    "def tune_thresholds_per_label(Y_true: np.ndarray, scores: np.ndarray, mode: str, n_thr: int = 61) -> np.ndarray:\n",
    "    n_labels = Y_true.shape[1]\n",
    "    thr_out = np.zeros(n_labels, dtype=np.float32)\n",
    "    q = np.linspace(0.01, 0.99, n_thr)\n",
    "\n",
    "    for j in range(n_labels):\n",
    "        y = Y_true[:, j].astype(np.int8)\n",
    "        s = scores[:, j].astype(np.float32)\n",
    "\n",
    "        if int(y.sum()) == 0:\n",
    "            thr_out[j] = 1.0 if mode == \"proba\" else float(np.max(s) + 1.0)\n",
    "            continue\n",
    "\n",
    "        thr_grid = np.unique(np.quantile(s, q))\n",
    "        if thr_grid.size < 10:\n",
    "            mn, mx = float(np.min(s)), float(np.max(s))\n",
    "            thr_grid = np.array([mn], dtype=np.float32) if mn == mx else np.linspace(mn, mx, num=31, dtype=np.float32)\n",
    "\n",
    "        best_f1 = -1.0\n",
    "        best_thr = float(thr_grid[len(thr_grid)//2])\n",
    "\n",
    "        for thr in thr_grid:\n",
    "            pred = (s >= thr).astype(np.int8)\n",
    "            tp = int(((y == 1) & (pred == 1)).sum())\n",
    "            fp = int(((y == 0) & (pred == 1)).sum())\n",
    "            fn = int(((y == 1) & (pred == 0)).sum())\n",
    "            _, _, f1 = prf_from_counts(tp, fp, fn)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_thr = float(thr)\n",
    "        thr_out[j] = best_thr\n",
    "\n",
    "    return thr_out\n",
    "\n",
    "def apply_thresholds(scores: np.ndarray, thresholds: np.ndarray) -> np.ndarray:\n",
    "    return (scores >= thresholds.reshape(1, -1)).astype(np.int8)\n",
    "\n",
    "def per_label_metrics_df(Y_true: np.ndarray, Y_pred: np.ndarray, thresholds: np.ndarray) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for j, lab in enumerate(y_cols):\n",
    "        y = Y_true[:, j]; p = Y_pred[:, j]\n",
    "        tp = int(((y==1) & (p==1)).sum())\n",
    "        fp = int(((y==0) & (p==1)).sum())\n",
    "        fn = int(((y==1) & (p==0)).sum())\n",
    "        tn = int(((y==0) & (p==0)).sum())\n",
    "        prec, rec, f1 = prf_from_counts(tp, fp, fn)\n",
    "        rows.append({\n",
    "            \"label\": lab,\n",
    "            \"support_pos\": int(y.sum()),\n",
    "            \"tp\": tp, \"fp\": fp, \"fn\": fn, \"tn\": tn,\n",
    "            \"precision\": prec, \"recall\": rec, \"f1\": f1,\n",
    "            \"threshold\": float(thresholds[j]),\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0106cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available SMOTE models:\n",
      " - ovr_logreg_smote_C1\n",
      " - ovr_logreg_smote_C2\n",
      " - ovr_linearsvc_smote_C1\n",
      " - ovr_sgd_logloss_smote\n",
      " - ovr_sgd_hinge_smote\n"
     ]
    }
   ],
   "source": [
    "#CELL 4 — Model registry (SMOTE pipeline) + siz tanlaysiz (manual)\n",
    "def make_smote_ovr(model_name: str):\n",
    "    # # SVD: sparse -> dense low-dim\n",
    "    # n_comp = min(SVD_N_COMPONENTS, X_train.shape[1]-1) if X_train.shape[1] > 1 else 1\n",
    "    # svd = TruncatedSVD(n_components=n_comp, random_state=RANDOM_STATE)\n",
    "\n",
    "    # SMOTE (SVD space’da)\n",
    "    smote = SMOTE(\n",
    "        sampling_strategy=\"auto\",\n",
    "        k_neighbors=3,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    if model_name == \"ovr_logreg_smote_C1\":\n",
    "        base = LogisticRegression(solver=\"liblinear\", max_iter=3000, C=1.0, class_weight=None)\n",
    "    elif model_name == \"ovr_logreg_smote_C2\":\n",
    "        base = LogisticRegression(solver=\"liblinear\", max_iter=3000, C=2.0, class_weight=None)\n",
    "    elif model_name == \"ovr_linearsvc_smote_C1\":\n",
    "        base = LinearSVC(C=1.0, random_state=RANDOM_STATE)\n",
    "    elif model_name == \"ovr_sgd_logloss_smote\":\n",
    "        base = SGDClassifier(loss=\"log_loss\", alpha=1e-5, max_iter=2000, tol=1e-3, random_state=RANDOM_STATE)\n",
    "    elif model_name == \"ovr_sgd_hinge_smote\":\n",
    "        base = SGDClassifier(loss=\"hinge\", alpha=1e-5, max_iter=2000, tol=1e-3, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model_name\")\n",
    "\n",
    "    # OneVsRest har label uchun alohida fit qiladi -> pipeline ichidagi SMOTE ham har labelga alohida ishlaydi\n",
    "    pipe = ImbPipeline([\n",
    "        (\"smote\", smote),\n",
    "        (\"clf\", base),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # pipe = ImbPipeline([\n",
    "    #     (\"svd\", svd),\n",
    "    #     (\"smote\", smote),\n",
    "    #     (\"clf\", base),\n",
    "    # ])\n",
    "\n",
    "    return OneVsRestClassifier(pipe, n_jobs=N_JOBS)\n",
    "\n",
    "AVAILABLE_MODELS = [\n",
    "    \"ovr_logreg_smote_C1\",\n",
    "    \"ovr_logreg_smote_C2\",\n",
    "    \"ovr_linearsvc_smote_C1\",\n",
    "    \"ovr_sgd_logloss_smote\",\n",
    "    \"ovr_sgd_hinge_smote\",\n",
    "]\n",
    "\n",
    "print(\"Available SMOTE models:\")\n",
    "for m in AVAILABLE_MODELS:\n",
    "    print(\" -\", m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7725e929",
   "metadata": {},
   "source": [
    "# ovr_logreg_smote_C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de23fa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: ovr_logreg_smote_C1\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"ovr_logreg_smote_C1\"   # <-- har safar shu nomni o'zgartirib RUN qilamiz\n",
    "clf = make_smote_ovr(MODEL_NAME)\n",
    "print(\"Selected:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cbc423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "TRAIN (SMOTE): ovr_logreg_smote_C1\n",
      "==========================================================================================\n",
      "Score mode: proba | S_val shape: (24410, 21)\n",
      "VAL micro_f1: 0.9784687194157947 | macro_f1: 0.9440208168219181\n",
      "✅ Saved model: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\\Models\\improvement_models\\with_SMOTE_improvement_train\\ovr_logreg_smote_C1.joblib\n",
      "✅ Saved thresholds: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\\Models\\improvement_models\\with_SMOTE_improvement_train\\ovr_logreg_smote_C1_thresholds.json\n",
      "✅ Saved VAL metrics: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\\results\\improvement_smote\\smote_20260225_233337\\ovr_logreg_smote_C1_val_per_label_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>support_pos</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>y_pregnancy_reproductive</td>\n",
       "      <td>347</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>24063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265130</td>\n",
       "      <td>0.419134</td>\n",
       "      <td>0.999920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>y_hepatic</td>\n",
       "      <td>844</td>\n",
       "      <td>844</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>23368</td>\n",
       "      <td>0.809981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895016</td>\n",
       "      <td>0.110211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>y_hypersensitivity_allergy</td>\n",
       "      <td>771</td>\n",
       "      <td>643</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>23639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833982</td>\n",
       "      <td>0.909477</td>\n",
       "      <td>0.991319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>y_metabolic_endocrine</td>\n",
       "      <td>1256</td>\n",
       "      <td>1256</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>22969</td>\n",
       "      <td>0.871617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931405</td>\n",
       "      <td>0.125102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y_edema_swelling</td>\n",
       "      <td>1600</td>\n",
       "      <td>1441</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>22810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900625</td>\n",
       "      <td>0.947715</td>\n",
       "      <td>0.981808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>y_injury_accident</td>\n",
       "      <td>1718</td>\n",
       "      <td>1718</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>22571</td>\n",
       "      <td>0.934203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965983</td>\n",
       "      <td>0.124604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>y_ocular_visual</td>\n",
       "      <td>1106</td>\n",
       "      <td>1042</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>23304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942134</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>0.919523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>y_renal</td>\n",
       "      <td>618</td>\n",
       "      <td>612</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>23761</td>\n",
       "      <td>0.951788</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.970658</td>\n",
       "      <td>0.872241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>y_urinary</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>23767</td>\n",
       "      <td>0.958009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978554</td>\n",
       "      <td>0.387112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y_cardiovascular</td>\n",
       "      <td>2528</td>\n",
       "      <td>2528</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>21773</td>\n",
       "      <td>0.958665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978896</td>\n",
       "      <td>0.280250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label  support_pos    tp   fp   fn     tn  precision  \\\n",
       "16    y_pregnancy_reproductive          347    92    0  255  24063   1.000000   \n",
       "6                    y_hepatic          844   844  198    0  23368   0.809981   \n",
       "7   y_hypersensitivity_allergy          771   643    0  128  23639   1.000000   \n",
       "11       y_metabolic_endocrine         1256  1256  185    0  22969   0.871617   \n",
       "2             y_edema_swelling         1600  1441    0  159  22810   1.000000   \n",
       "10           y_injury_accident         1718  1718  121    0  22571   0.934203   \n",
       "14             y_ocular_visual         1106  1042    0   64  23304   1.000000   \n",
       "18                     y_renal          618   612   31    6  23761   0.951788   \n",
       "20                   y_urinary          616   616   27    0  23767   0.958009   \n",
       "0             y_cardiovascular         2528  2528  109    0  21773   0.958665   \n",
       "\n",
       "      recall        f1  threshold  \n",
       "16  0.265130  0.419134   0.999920  \n",
       "6   1.000000  0.895016   0.110211  \n",
       "7   0.833982  0.909477   0.991319  \n",
       "11  1.000000  0.931405   0.125102  \n",
       "2   0.900625  0.947715   0.981808  \n",
       "10  1.000000  0.965983   0.124604  \n",
       "14  0.942134  0.970205   0.919523  \n",
       "18  0.990291  0.970658   0.872241  \n",
       "20  1.000000  0.978554   0.387112  \n",
       "0   1.000000  0.978896   0.280250  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CELL 5 — Train (manual) + VAL threshold tuning + SAVE (siz bitta bosasiz)\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"TRAIN (SMOTE):\", MODEL_NAME)\n",
    "print(\"=\"*90)\n",
    "\n",
    "# fit\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# VAL scores\n",
    "S_val, mode = score_matrix(clf, X_val)\n",
    "print(\"Score mode:\", mode, \"| S_val shape:\", S_val.shape)\n",
    "\n",
    "# thresholds on VAL\n",
    "thr = tune_thresholds_per_label(Y_val, S_val, mode=mode, n_thr=N_THR)\n",
    "Y_val_pred = apply_thresholds(S_val, thr)\n",
    "\n",
    "val_overall = multilabel_micro_macro(Y_val, Y_val_pred)\n",
    "print(\"VAL micro_f1:\", val_overall[\"micro_f1\"], \"| macro_f1:\", val_overall[\"macro_f1\"])\n",
    "\n",
    "val_per_label = per_label_metrics_df(Y_val, Y_val_pred, thr)\n",
    "\n",
    "# ---- SAVE model + thresholds ----\n",
    "model_path = SAVE_DIR / f\"{MODEL_NAME}.joblib\"\n",
    "thr_path   = SAVE_DIR / f\"{MODEL_NAME}_thresholds.json\"\n",
    "\n",
    "joblib.dump(clf, model_path)\n",
    "\n",
    "thr_dict = {lab.replace(\"y_\", \"\", 1): float(t) for lab, t in zip(y_cols, thr)}\n",
    "with open(thr_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(thr_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Saved model:\", model_path.resolve())\n",
    "print(\"✅ Saved thresholds:\", thr_path.resolve())\n",
    "\n",
    "# ---- SAVE metrics ----\n",
    "val_per_label.to_csv(RESULTS_DIR / f\"{MODEL_NAME}_val_per_label_metrics.csv\", index=False)\n",
    "with open(RESULTS_DIR / f\"{MODEL_NAME}_val_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"model\": MODEL_NAME, \"mode\": mode, **val_overall}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Saved VAL metrics:\", (RESULTS_DIR / f\"{MODEL_NAME}_val_per_label_metrics.csv\").resolve())\n",
    "\n",
    "val_per_label.sort_values(\"f1\").head(10)\n",
    "\n",
    "# 66 minut ketdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL 6 — (ixtiyoriy) TEST baholash (VAL threshold bilan) + save\n",
    "S_test, _ = score_matrix(clf, X_test)\n",
    "Y_test_pred = apply_thresholds(S_test, thr)\n",
    "\n",
    "test_overall = multilabel_micro_macro(Y_test, Y_test_pred)\n",
    "print(\"TEST micro_f1:\", test_overall[\"micro_f1\"], \"| macro_f1:\", test_overall[\"macro_f1\"])\n",
    "\n",
    "test_per_label = per_label_metrics_df(Y_test, Y_test_pred, thr)\n",
    "test_per_label.to_csv(RESULTS_DIR / f\"{MODEL_NAME}_test_per_label_metrics.csv\", index=False)\n",
    "\n",
    "with open(RESULTS_DIR / f\"{MODEL_NAME}_test_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"model\": MODEL_NAME, **test_overall}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Saved TEST metrics:\", (RESULTS_DIR / f\"{MODEL_NAME}_test_per_label_metrics.csv\").resolve())\n",
    "\n",
    "# Sizning workflow (bitta-bitta bosib)\n",
    "\n",
    "# CELL 1–3: bir marta run\n",
    "\n",
    "# Har model uchun:\n",
    "\n",
    "# CELL 4’da MODEL_NAME ni o‘zgartirasiz\n",
    "\n",
    "# CELL 5 ni bosasiz (train + save)\n",
    "\n",
    "# xohlasangiz CELL 6 (test)\n",
    "\n",
    "# Model saqlanadigan joy doim:\n",
    "# Models/improvement_models/with_SMOTE_improvement_train/\n",
    "\n",
    "# Root ham endi adashmaydi, chunki u Data/Feature_Selected yoki Data/Engineered_data bor joydan topyapti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee2b01",
   "metadata": {},
   "source": [
    "# ovr_logreg_smote_C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50c214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5a572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc2a0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53bc75ef",
   "metadata": {},
   "source": [
    "# ovr_linearsvc_smote_C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397bb5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ca238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca8ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8cbb97d",
   "metadata": {},
   "source": [
    "# ovr_sgd_logloss_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261a1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e91b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45411556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee30db50",
   "metadata": {},
   "source": [
    "# ovr_sgd_hinge_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee4b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5cafbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b5fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bbc686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf697e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_folder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
