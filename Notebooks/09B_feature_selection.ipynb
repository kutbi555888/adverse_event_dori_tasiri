{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84054eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quyida Data/Engineered_data/fe_v1/ (X/Y) dan o‘qib, Chi-square (chi2) bo‘yicha top-k per label qilib feature selection qiladigan kodlar.\n",
    "\n",
    "# 09B_feature_selection (Notebook cell’lari)\n",
    "# CELL 1 — Imports\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1e0afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\n",
      "ENGINEERED_IN: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\\Data\\Engineered_data\\fe_v1\n",
      "Num labels: 21\n",
      "X shapes: (201176, 104479) (24410, 104479) (24164, 104479)\n",
      "Y shapes: (201176, 21) (24410, 21) (24164, 21)\n"
     ]
    }
   ],
   "source": [
    "#CELL 2 — Config + PROJECT_ROOT + Load Engineered Data (fe_v1)\n",
    "FE_VERSION_IN = \"fe_v1\"              # 09_feature_engineering chiqargan\n",
    "FS_VERSION_OUT = \"fe_v1_fs_chi2_v1\"  # yangi selected_data versiya\n",
    "\n",
    "# Har label uchun nechta feature olish\n",
    "TOPK_PER_LABEL = 3000\n",
    "\n",
    "# Final feature sonini cheklash (union juda kattalashsa)\n",
    "MAX_TOTAL_FEATURES = 250000\n",
    "\n",
    "# Meta (oxirgi 3 ta) feature’ni majburan qoldiramiz\n",
    "KEEP_META_LAST_N = 3\n",
    "\n",
    "ENGINEERED_DIR_NAME = \"Engineered_data\"\n",
    "\n",
    "def find_project_root_by_engineered(start: Path | None = None):\n",
    "    start = start or Path.cwd()\n",
    "    checked = []\n",
    "    for p in [start] + list(start.parents):\n",
    "        ed = p / \"Data\" / ENGINEERED_DIR_NAME / FE_VERSION_IN\n",
    "        checked.append(ed)\n",
    "        if (ed / \"X_train.npz\").exists() and (ed / \"Y_train.npy\").exists() and (ed / \"engineered_meta.json\").exists():\n",
    "            return p, ed\n",
    "    raise FileNotFoundError(\n",
    "        \"Engineered data topilmadi.\\n\"\n",
    "        f\"Start: {start.resolve()}\\n\"\n",
    "        \"Oxirgi 10 yo‘l:\\n\" + \"\\n\".join(str(x) for x in checked[-10:]) +\n",
    "        \"\\nYe chim: avval 09_feature_engineering ni run qiling.\"\n",
    "    )\n",
    "\n",
    "PROJECT_ROOT, ENGINEERED_IN = find_project_root_by_engineered()\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT.resolve())\n",
    "print(\"ENGINEERED_IN:\", ENGINEERED_IN.resolve())\n",
    "\n",
    "# Load meta\n",
    "with open(ENGINEERED_IN / \"engineered_meta.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "y_cols = meta[\"y_cols\"]\n",
    "print(\"Num labels:\", len(y_cols))\n",
    "\n",
    "# Load X/Y\n",
    "X_train = sparse.load_npz(ENGINEERED_IN / \"X_train.npz\").tocsr()\n",
    "X_val   = sparse.load_npz(ENGINEERED_IN / \"X_val.npz\").tocsr()\n",
    "X_test  = sparse.load_npz(ENGINEERED_IN / \"X_test.npz\").tocsr()\n",
    "\n",
    "Y_train = np.load(ENGINEERED_IN / \"Y_train.npy\")\n",
    "Y_val   = np.load(ENGINEERED_IN / \"Y_val.npy\")\n",
    "Y_test  = np.load(ENGINEERED_IN / \"Y_test.npy\")\n",
    "\n",
    "print(\"X shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"Y shapes:\", Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7c3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "_term_split = re.compile(r\"\\s*;\\s*\")\n",
    "\n",
    "def meta_to_sparse(texts):\n",
    "    # 09’da ishlatilgan meta feature’lar bilan bir xil bo‘lishi kerak\n",
    "    lens = []\n",
    "    n_terms = []\n",
    "    n_uniq_terms = []\n",
    "\n",
    "    for s in texts:\n",
    "        s = (s or \"\").strip()\n",
    "        lens.append(len(s))\n",
    "        if not s:\n",
    "            n_terms.append(0)\n",
    "            n_uniq_terms.append(0)\n",
    "            continue\n",
    "        terms = [t.strip().lower() for t in _term_split.split(s) if t.strip()]\n",
    "        n_terms.append(len(terms))\n",
    "        n_uniq_terms.append(len(set(terms)))\n",
    "\n",
    "    lens = np.array(lens, dtype=np.float32).reshape(-1, 1)\n",
    "    n_terms = np.array(n_terms, dtype=np.float32).reshape(-1, 1)\n",
    "    n_uniq_terms = np.array(n_uniq_terms, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "    feats = np.hstack([np.log1p(lens), n_terms, n_uniq_terms]).astype(np.float32)\n",
    "    return sparse.csr_matrix(feats)\n",
    "\n",
    "# Shu bilan joblib.load() o‘tadi.\n",
    "\n",
    "# Nega ishlaydi?\n",
    "# Pickle ichida __main__.meta_to_sparse deb yozilgan. Siz uni notebook’da aynan shu nom bilan yaratib qo‘ysangiz, loader topadi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e55479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names: (104479,)\n"
     ]
    }
   ],
   "source": [
    "# CELL 3 — (Ixtiyoriy) Feature names’ni olish (featurizer artifact bo‘lsa)\n",
    "\n",
    "# Agar artifacts/feature_engineering/fe_v1/featurizer...joblib mavjud bo‘lsa, feature name ham saqlab qo‘yamiz. Yo‘q bo‘lsa, selection baribir ishlaydi.\n",
    "\n",
    "FEATURIZER_PATH = PROJECT_ROOT / \"artifacts\" / \"feature_engineering\" / FE_VERSION_IN / \"featurizer_union_word_char_meta.joblib\"\n",
    "\n",
    "feature_names = None\n",
    "if FEATURIZER_PATH.exists():\n",
    "    featurizer = joblib.load(FEATURIZER_PATH)\n",
    "    # FeatureUnion ichidan feature names yig'amiz\n",
    "    names = []\n",
    "    for name, tr in featurizer.transformer_list:\n",
    "        if hasattr(tr, \"get_feature_names_out\"):\n",
    "            fn = tr.get_feature_names_out()\n",
    "            names.extend([f\"{name}__{x}\" for x in fn])\n",
    "        else:\n",
    "            # meta transformer uchun (3 ta) nom beramiz\n",
    "            if name == \"meta\":\n",
    "                names.extend([\"meta__log1p_len\", \"meta__n_terms\", \"meta__n_uniq_terms\"])\n",
    "            else:\n",
    "                names.extend([f\"{name}__feat{i}\" for i in range(tr.transform(X_train[:1]).shape[1])])\n",
    "    feature_names = np.array(names, dtype=object)\n",
    "    print(\"feature_names:\", feature_names.shape)\n",
    "else:\n",
    "    print(\"Featurizer artifact topilmadi (ok) — feature_names saqlanmaydi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e17963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forced meta idx: [104476, 104477, 104478]\n",
      "Selected features: 33671 / 104479\n"
     ]
    }
   ],
   "source": [
    "#CELL 4 — Chi2 feature selection (top-k per label, union)\n",
    "n_samples, n_features = X_train.shape\n",
    "n_labels = Y_train.shape[1]\n",
    "\n",
    "selected = set()\n",
    "\n",
    "# Meta (oxirgi N) ni majburan qoldiramiz\n",
    "if KEEP_META_LAST_N and KEEP_META_LAST_N > 0:\n",
    "    meta_idx = list(range(n_features - KEEP_META_LAST_N, n_features))\n",
    "    for i in meta_idx:\n",
    "        if 0 <= i < n_features:\n",
    "            selected.add(i)\n",
    "    print(\"Forced meta idx:\", meta_idx)\n",
    "\n",
    "# Har label bo‘yicha chi2 top-k\n",
    "for j in range(n_labels):\n",
    "    y = Y_train[:, j].astype(np.int8)\n",
    "\n",
    "    # label’da positive umuman bo‘lmasa skip\n",
    "    if int(y.sum()) == 0:\n",
    "        continue\n",
    "\n",
    "    scores, _ = chi2(X_train, y)  # X non-negative bo‘lishi shart (TF-IDF OK)\n",
    "    scores = np.nan_to_num(scores, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    k = min(TOPK_PER_LABEL, n_features)\n",
    "    top_idx = np.argpartition(scores, -k)[-k:]\n",
    "    for idx in top_idx:\n",
    "        selected.add(int(idx))\n",
    "\n",
    "    # union juda kattalashsa: kesamiz\n",
    "    if len(selected) > MAX_TOTAL_FEATURES:\n",
    "        print(\"Reached MAX_TOTAL_FEATURES, stopping early at label:\", j)\n",
    "        break\n",
    "\n",
    "selected = np.array(sorted(selected), dtype=np.int32)\n",
    "print(\"Selected features:\", selected.size, \"/\", n_features)\n",
    "\n",
    "mask = np.zeros(n_features, dtype=bool)\n",
    "mask[selected] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e818c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_fs: (201176, 33671)\n",
      "X_val_fs  : (24410, 33671)\n",
      "X_test_fs : (24164, 33671)\n"
     ]
    }
   ],
   "source": [
    "#CELL 5 — Apply selection: X_train/val/test ni kamaytirish\n",
    "X_train_fs = X_train[:, mask]\n",
    "X_val_fs   = X_val[:, mask]\n",
    "X_test_fs  = X_test[:, mask]\n",
    "\n",
    "print(\"X_train_fs:\", X_train_fs.shape)\n",
    "print(\"X_val_fs  :\", X_val_fs.shape)\n",
    "print(\"X_test_fs :\", X_test_fs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa5f522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_DIR: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\\Data\\Feature_Selected\\fe_v1_fs_chi2_v1\n",
      "Saved X_*.npz\n",
      "Saved Y_*.npy\n",
      "Saved feature_mask.npy + selected_idx.npy\n",
      "Saved feature_selector.joblib\n",
      "Saved engineered_meta.json\n",
      "Saved selected_feature_names.npy/.txt\n",
      "✅ Saved Feature_Selected data: C:\\Users\\xolmu\\OneDrive\\Desktop\\Modul Program oyi\\Modul_Program3\\6_project_dori_tasiri_extract\\Data\\Feature_Selected\\fe_v1_fs_chi2_v1\n"
     ]
    }
   ],
   "source": [
    "#CELL 6 — Save to Data/Feature_Selected/<FS_VERSION_OUT>/\n",
    "# =========================================================\n",
    "# CELL 6 — Save feature-selected data to Data/Feature_Selected\n",
    "# =========================================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "FEATURE_SELECTED_DIRNAME = \"Feature_Selected\"\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / \"Data\" / FEATURE_SELECTED_DIRNAME / FS_VERSION_OUT\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())\n",
    "\n",
    "# --- Save X (selected) ---\n",
    "sparse.save_npz(OUT_DIR / \"X_train.npz\", X_train_fs)\n",
    "sparse.save_npz(OUT_DIR / \"X_val.npz\", X_val_fs)\n",
    "sparse.save_npz(OUT_DIR / \"X_test.npz\", X_test_fs)\n",
    "print(\"Saved X_*.npz\")\n",
    "\n",
    "# --- Save Y (unchanged) ---\n",
    "np.save(OUT_DIR / \"Y_train.npy\", Y_train.astype(np.int8))\n",
    "np.save(OUT_DIR / \"Y_val.npy\", Y_val.astype(np.int8))\n",
    "np.save(OUT_DIR / \"Y_test.npy\", Y_test.astype(np.int8))\n",
    "print(\"Saved Y_*.npy\")\n",
    "\n",
    "# --- Save mask + selected idx ---\n",
    "np.save(OUT_DIR / \"feature_mask.npy\", mask)\n",
    "np.save(OUT_DIR / \"selected_idx.npy\", selected)\n",
    "print(\"Saved feature_mask.npy + selected_idx.npy\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "selector_payload = {\n",
    "    \"mask\": mask,                 # bool array\n",
    "    \"selected_idx\": selected,     # int indices\n",
    "    \"fs_version_out\": FS_VERSION_OUT,\n",
    "    \"method\": \"chi2_topk_per_label_union\",\n",
    "    \"topk_per_label\": TOPK_PER_LABEL,\n",
    "    \"max_total_features\": MAX_TOTAL_FEATURES,\n",
    "    \"keep_meta_last_n\": KEEP_META_LAST_N,\n",
    "}\n",
    "\n",
    "# agar selected_feature_names.npy saqlayotgan bo‘lsangiz, uni ham qo‘shsa bo‘ladi:\n",
    "if \"feature_names\" in globals() and feature_names is not None and len(feature_names) == n_features:\n",
    "    selector_payload[\"selected_feature_names\"] = feature_names[mask]\n",
    "\n",
    "joblib.dump(selector_payload, OUT_DIR / \"feature_selector.joblib\")\n",
    "print(\"Saved feature_selector.joblib\")\n",
    "\n",
    "# --- Copy IDs/idx from engineered input (if exists) ---\n",
    "for fn in [\"ids_train.csv\", \"ids_val.csv\", \"ids_test.csv\", \"idx_train.npy\", \"idx_val.npy\", \"idx_test.npy\"]:\n",
    "    src = ENGINEERED_IN / fn\n",
    "    if src.exists():\n",
    "        (OUT_DIR / fn).write_bytes(src.read_bytes())\n",
    "\n",
    "# --- Save meta ---\n",
    "out_meta = dict(meta)\n",
    "out_meta.update({\n",
    "    \"fe_version_in\": FE_VERSION_IN,\n",
    "    \"fs_version_out\": FS_VERSION_OUT,\n",
    "    \"method\": \"chi2_topk_per_label_union\",\n",
    "    \"topk_per_label\": TOPK_PER_LABEL,\n",
    "    \"max_total_features\": MAX_TOTAL_FEATURES,\n",
    "    \"keep_meta_last_n\": KEEP_META_LAST_N,\n",
    "    \"selected_features\": int(selected.size),\n",
    "    \"original_features\": int(n_features),\n",
    "    \"output_dir\": str(OUT_DIR),\n",
    "    \"X_shapes\": {\n",
    "        \"train\": [int(X_train_fs.shape[0]), int(X_train_fs.shape[1])],\n",
    "        \"val\":   [int(X_val_fs.shape[0]), int(X_val_fs.shape[1])],\n",
    "        \"test\":  [int(X_test_fs.shape[0]), int(X_test_fs.shape[1])],\n",
    "    },\n",
    "    \"Y_shapes\": {\n",
    "        \"train\": [int(Y_train.shape[0]), int(Y_train.shape[1])],\n",
    "        \"val\":   [int(Y_val.shape[0]), int(Y_val.shape[1])],\n",
    "        \"test\":  [int(Y_test.shape[0]), int(Y_test.shape[1])],\n",
    "    },\n",
    "})\n",
    "\n",
    "with open(OUT_DIR / \"engineered_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(out_meta, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved engineered_meta.json\")\n",
    "\n",
    "# --- Save feature names (if available) ---\n",
    "if \"feature_names\" in globals() and feature_names is not None and len(feature_names) == n_features:\n",
    "    sel_names = feature_names[mask]\n",
    "    np.save(OUT_DIR / \"selected_feature_names.npy\", sel_names)\n",
    "    with open(OUT_DIR / \"selected_feature_names.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for x in sel_names.tolist():\n",
    "            f.write(str(x) + \"\\n\")\n",
    "    print(\"Saved selected_feature_names.npy/.txt\")\n",
    "\n",
    "print(\"✅ Saved Feature_Selected data:\", OUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10_train_improvement’da qanday o‘qiladi?\n",
    "\n",
    "# Endi 10’da Engineered_data emas, Feature_Selected dan o‘qitasiz:\n",
    "\n",
    "# FS_VERSION_OUT = \"fe_v1_fs_chi2_v1\"\n",
    "# FEATURE_SELECTED_DIR = PROJECT_ROOT / \"Data\" / \"Feature_Selected\" / FS_VERSION_OUT\n",
    "# X_train = sparse.load_npz(FEATURE_SELECTED_DIR / \"X_train.npz\")\n",
    "# Y_train = np.load(FEATURE_SELECTED_DIR / \"Y_train.npy\")\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4638d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10_train_improvement uchun nima o‘zgaradi?\n",
    "\n",
    "# Endi 10_train_improvement’da faqat shu 2 ta config o‘zgaradi:\n",
    "\n",
    "# FE_VERSION = \"fe_v1_fs_chi2_v1\"\n",
    "# # va ENGINEERED_DIR ni shu versiyadan o‘qiydi\n",
    "\n",
    "# Shunda model kamroq feature bilan tezroq train bo‘ladi va ko‘pincha generalization yaxshilanadi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b712610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c12037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c00a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eea2d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef18ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35444ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16eb4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2433e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4cde2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_folder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
